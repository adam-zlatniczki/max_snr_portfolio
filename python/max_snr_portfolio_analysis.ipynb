{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from pandas_datareader import data as pdr\n",
    "import yfinance as yf\n",
    "import streamlit as st\n",
    "import numpy as np\n",
    "\n",
    "from statsmodels.tsa.stattools import acf\n",
    "from scipy.stats import wilcoxon, hmean\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from multiprocess import Pool\n",
    "import multiprocessing\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sb\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', '.*distplot.*', )\n",
    "\n",
    "from optimal_weights import random_portfolio, min_var_portfolio, max_snr_portfolio\n",
    "from evaluate_weights import evaluate_weights"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download historical prices (adjusted close)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "symbols=['AAPL', 'NKE', 'GOOGL', 'AMZN']\n",
    "start = '2005-01-01' # expected datetime format is '%Y-%m-%d'\n",
    "end = '2022-12-31'   # expected datetime format is '%Y-%m-%d'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-09 11:16:27.357 \n",
      "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run c:\\Users\\edmzlat\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py [ARGUMENTS]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AAPL</th>\n",
       "      <th>NKE</th>\n",
       "      <th>GOOGL</th>\n",
       "      <th>AMZN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2005-01-03 00:00:00</th>\n",
       "      <td>0.963385</td>\n",
       "      <td>9.136415</td>\n",
       "      <td>5.072823</td>\n",
       "      <td>2.2260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-01-04 00:00:00</th>\n",
       "      <td>0.973278</td>\n",
       "      <td>9.006457</td>\n",
       "      <td>4.867367</td>\n",
       "      <td>2.1070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-01-05 00:00:00</th>\n",
       "      <td>0.981803</td>\n",
       "      <td>8.898663</td>\n",
       "      <td>4.842593</td>\n",
       "      <td>2.0885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-01-06 00:00:00</th>\n",
       "      <td>0.982564</td>\n",
       "      <td>8.887582</td>\n",
       "      <td>4.718468</td>\n",
       "      <td>2.0525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-01-07 00:00:00</th>\n",
       "      <td>1.054106</td>\n",
       "      <td>8.835194</td>\n",
       "      <td>4.851101</td>\n",
       "      <td>2.1160</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         AAPL       NKE     GOOGL    AMZN\n",
       "2005-01-03 00:00:00  0.963385  9.136415  5.072823  2.2260\n",
       "2005-01-04 00:00:00  0.973278  9.006457  4.867367  2.1070\n",
       "2005-01-05 00:00:00  0.981803  8.898663  4.842593  2.0885\n",
       "2005-01-06 00:00:00  0.982564  8.887582  4.718468  2.0525\n",
       "2005-01-07 00:00:00  1.054106  8.835194  4.851101  2.1160"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yf.pdr_override()\n",
    "price_df = pd.DataFrame()\n",
    "\n",
    "for symbol in symbols:\n",
    "    user_input = st.text_input('Enter Stock Ticker', symbol)\n",
    "    tmp_df = pdr.get_data_yahoo(user_input, start=start, end=end)\n",
    "    price_df = pd.concat([price_df, tmp_df['Adj Close']], axis='columns')\n",
    "\n",
    "price_df.columns = symbols\n",
    "price_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AAPL</th>\n",
       "      <th>NKE</th>\n",
       "      <th>GOOGL</th>\n",
       "      <th>AMZN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4530.000000</td>\n",
       "      <td>4530.000000</td>\n",
       "      <td>4530.000000</td>\n",
       "      <td>4530.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.001301</td>\n",
       "      <td>0.000725</td>\n",
       "      <td>0.000809</td>\n",
       "      <td>0.001095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.020858</td>\n",
       "      <td>0.018051</td>\n",
       "      <td>0.018956</td>\n",
       "      <td>0.024336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-0.179195</td>\n",
       "      <td>-0.128081</td>\n",
       "      <td>-0.116341</td>\n",
       "      <td>-0.218220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.008611</td>\n",
       "      <td>-0.007687</td>\n",
       "      <td>-0.007847</td>\n",
       "      <td>-0.009981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.001001</td>\n",
       "      <td>0.000577</td>\n",
       "      <td>0.000690</td>\n",
       "      <td>0.000560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.011993</td>\n",
       "      <td>0.009021</td>\n",
       "      <td>0.009770</td>\n",
       "      <td>0.012229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.139049</td>\n",
       "      <td>0.155315</td>\n",
       "      <td>0.199915</td>\n",
       "      <td>0.269497</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              AAPL          NKE        GOOGL         AMZN\n",
       "count  4530.000000  4530.000000  4530.000000  4530.000000\n",
       "mean      0.001301     0.000725     0.000809     0.001095\n",
       "std       0.020858     0.018051     0.018956     0.024336\n",
       "min      -0.179195    -0.128081    -0.116341    -0.218220\n",
       "25%      -0.008611    -0.007687    -0.007847    -0.009981\n",
       "50%       0.001001     0.000577     0.000690     0.000560\n",
       "75%       0.011993     0.009021     0.009770     0.012229\n",
       "max       0.139049     0.155315     0.199915     0.269497"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "price_df.pct_change().describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Take independent subsamples (windows) from the data and generate portfolios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_largest_significant_lags(df, alfa=0.05):\n",
    "    largest_significant_lag = 0\n",
    "    \n",
    "    for i in range(df.shape[1]):\n",
    "        significant_lags = np.where(acf(df.iloc[:, i], missing=\"conservative\", qstat=True)[-1] < alfa)[0]\n",
    "\n",
    "        if significant_lags.shape[0] == 0:\n",
    "            largest_significant_lag = max(largest_significant_lag, 0)\n",
    "        else:\n",
    "            # zero lag is ignored in the LB-test, so the index must be shifted by 1\n",
    "            largest_significant_lag = max(largest_significant_lag, significant_lags[-1] + 1)\n",
    "    \n",
    "    return largest_significant_lag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0c4d5e82c3144d593481e55b7d9c484",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4531 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8cc9298ab5347ec9adbe3d848841bc3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fdc094d0df84fb689c78997d7d1417b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "408989b8f51f4ff68f8cff38dda7f330",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a8864fbb07c4d68937ca49ed0783135",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4b6779db9e94513ac485f43461b4373",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8e8e3f8a10f4337b0a0faeb65254101",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\edmzlat\\Anaconda3\\lib\\site-packages\\multiprocess\\pool.py\u001b[0m in \u001b[0;36mnext\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    852\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 853\u001b[1;33m                 \u001b[0mitem\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_items\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpopleft\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    854\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: pop from an empty deque",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_29232\\3888956511.py\u001b[0m in \u001b[0;36m<cell line: 13>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     29\u001b[0m             \u001b[1;31m# find random portfolio Hurst exponent(s)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mPool\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmax_pool\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m                 pool_outputs = list(\n\u001b[0m\u001b[0;32m     32\u001b[0m                     tqdm(\n\u001b[0;32m     33\u001b[0m                         p.imap(\n",
      "\u001b[1;32mc:\\Users\\edmzlat\\Anaconda3\\lib\\site-packages\\tqdm\\notebook.py\u001b[0m in \u001b[0;36m__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    256\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    257\u001b[0m             \u001b[0mit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtqdm_notebook\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__iter__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 258\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mit\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    259\u001b[0m                 \u001b[1;31m# return super(tqdm...) will not catch exception\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    260\u001b[0m                 \u001b[1;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\edmzlat\\Anaconda3\\lib\\site-packages\\tqdm\\std.py\u001b[0m in \u001b[0;36m__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1193\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1194\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1195\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1196\u001b[0m                 \u001b[1;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1197\u001b[0m                 \u001b[1;31m# Update and possibly print the progressbar.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\edmzlat\\Anaconda3\\lib\\site-packages\\multiprocess\\pool.py\u001b[0m in \u001b[0;36mnext\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    856\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pool\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    857\u001b[0m                     \u001b[1;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 858\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    859\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    860\u001b[0m                     \u001b[0mitem\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_items\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpopleft\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\edmzlat\\Anaconda3\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    310\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m    \u001b[1;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    311\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 312\u001b[1;33m                 \u001b[0mwaiter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    313\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    314\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "window_size = 100\n",
    "num_portfolios = 10000\n",
    "max_pool = multiprocessing.cpu_count()\n",
    "\n",
    "\n",
    "window_start = 0\n",
    "window_end = window_size\n",
    "largest_significant_lag = 0\n",
    "num_assets = len(price_df.columns)\n",
    "\n",
    "results = []\n",
    "\n",
    "with tqdm(total=price_df.shape[0]) as pbar:\n",
    "\n",
    "    while window_start + window_size < price_df.shape[0]:\n",
    "        window_df = price_df.iloc[window_start:window_end, :]\n",
    "        \n",
    "        # find mean and covariance of returns\n",
    "        cov_matrix = window_df.pct_change().cov()\n",
    "        exp_returns = window_df.pct_change().mean()\n",
    "        \n",
    "        cumul_returns_df = window_df / window_df.iloc[0,:]\n",
    "        \n",
    "        for longonly in [True, False]:\n",
    "        \n",
    "            w_min_var = min_var_portfolio(cov_matrix, longonly=longonly)\n",
    "            w_max_snr = max_snr_portfolio(cov_matrix, exp_returns, longonly=longonly)\n",
    "\n",
    "            # find random portfolio Hurst exponent(s)\n",
    "            with Pool(max_pool) as p:\n",
    "                pool_outputs = list(\n",
    "                    tqdm(\n",
    "                        p.imap(\n",
    "                            random_portfolio,\n",
    "                            [(seed, num_assets, cumul_returns_df, longonly) for seed in range(num_portfolios)]\n",
    "                        ),\n",
    "                        total=num_portfolios\n",
    "                    )\n",
    "                )\n",
    "\n",
    "            results.append(\n",
    "                evaluate_weights(w_min_var, cumul_returns_df) +\n",
    "                evaluate_weights(w_max_snr, cumul_returns_df) +\n",
    "                [ sum(x)/float(len(pool_outputs)) for x in zip(*pool_outputs) ] +\n",
    "                [longonly]\n",
    "            )\n",
    "        \n",
    "        ### move window \n",
    "        largest_significant_lag = get_largest_significant_lags(window_df.pct_change(), alfa=0.05)\n",
    "        \n",
    "        window_start = window_end + largest_significant_lag\n",
    "        window_end = window_start + window_size\n",
    "\n",
    "        pbar.update(window_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(results, columns=[\"H1_minvar\", \"H2_minvar\", \"H3_minvar\", \"H4_minvar\", \"H1_maxsnr\", \"H2_maxsnr\", \"H3_maxsnr\", \"H4_maxsnr\", \"H1_random\", \"H2_random\", \"H3_random\", \"H4_random\", \"longonly\"])\n",
    "results_df.to_csv(\"results_df.csv\")\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze portfolios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.read_csv(\"results_df.csv\", index_col=0)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "portfolios = [\"maxsnr\", \"minvar\", \"random\"]\n",
    "\n",
    "# H1: rescaled range\n",
    "# H2: robust variance of lagged difference\n",
    "# H3: variance of lagged difference\n",
    "# H4: fractal dimensiong\n",
    "hurst_estimators = [\"H1\", \"H2\", \"H3\", \"H4\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check Hurst estimator distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "longonly = results_df.longonly == True\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(20, 14))\n",
    "fig.suptitle(\"Distributions of the different Hurst estimators\", fontsize=20)\n",
    "\n",
    "for j in range(len(hurst_estimators)):\n",
    "    for i in range(len(portfolios)):\n",
    "        ax = axes[j // 2][j % 2]\n",
    "        sb.distplot(results_df[longonly][hurst_estimators[j]+\"_\"+portfolios[i]], kde=True, label=portfolios[i], ax=ax)\n",
    "        ax.set_xlabel(hurst_estimators[j])\n",
    "        ax.legend(loc=\"upper right\")\n",
    "        ax.set_xlim(0.0, 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = results_df.longonly == False\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(20, 14))\n",
    "fig.suptitle(\"Distributions of the different Hurst estimators\", fontsize=20)\n",
    "\n",
    "for j in range(len(hurst_estimators)):\n",
    "    for i in range(len(portfolios)):\n",
    "        ax = axes[j // 2][j % 2]\n",
    "        sb.distplot(results_df[~longonly][hurst_estimators[j]+\"_\"+portfolios[i]], kde=True, label=portfolios[i], ax=ax)\n",
    "        ax.set_xlabel(hurst_estimators[j])\n",
    "        ax.legend(loc=\"upper right\")\n",
    "        ax.set_xlim(0.0, 1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypothesis test: equivalence of means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# H0: sample means are equal\n",
    "# H1: the first mean is larger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = []\n",
    "data = []\n",
    "\n",
    "# Test equivalence\n",
    "cntr = 0\n",
    "for i in range(len(portfolios)):\n",
    "    for j in range(i+1, len(portfolios)):\n",
    "        index.append((cntr, portfolios[i], \"mean\"))\n",
    "        data.append([results_df[longonly][hurst_estimator+\"_\"+portfolios[i]].mean() for hurst_estimator in hurst_estimators] + [\"\"])\n",
    "        \n",
    "        index.append((cntr, portfolios[j], \"mean\"))\n",
    "        data.append([results_df[longonly][hurst_estimator+\"_\"+portfolios[j]].mean() for hurst_estimator in hurst_estimators] + [\"\"])\n",
    "        \n",
    "        index.append((cntr, \"Wilcoxon\", \"T\"))\n",
    "        index.append((cntr, \"Wilcoxon\", \"p\"))\n",
    "        \n",
    "        data.append([wilcoxon(results_df[longonly][hurst_estimator+\"_\"+portfolios[i]], results_df[longonly][hurst_estimator+\"_\"+portfolios[j]], alternative=\"greater\")[0] for hurst_estimator in hurst_estimators] + [\"\"])\n",
    "        data.append([wilcoxon(results_df[longonly][hurst_estimator+\"_\"+portfolios[i]], results_df[longonly][hurst_estimator+\"_\"+portfolios[j]], alternative=\"greater\")[1] for hurst_estimator in hurst_estimators])\n",
    "        data[-1].append(hmean(data[-1]))\n",
    "        \n",
    "        cntr += 1\n",
    "\n",
    "pd.DataFrame(data, index=pd.MultiIndex.from_tuples(index), columns=hurst_estimators+[\"hmp\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = []\n",
    "data = []\n",
    "\n",
    "# Test equivalence\n",
    "cntr = 0\n",
    "for i in range(len(portfolios)):\n",
    "    for j in range(i+1, len(portfolios)):\n",
    "        index.append((cntr, portfolios[i], \"mean\"))\n",
    "        data.append([results_df[~longonly][hurst_estimator+\"_\"+portfolios[i]].mean() for hurst_estimator in hurst_estimators] + [\"\"])\n",
    "        \n",
    "        index.append((cntr, portfolios[j], \"mean\"))\n",
    "        data.append([results_df[~longonly][hurst_estimator+\"_\"+portfolios[j]].mean() for hurst_estimator in hurst_estimators] + [\"\"])\n",
    "        \n",
    "        index.append((cntr, \"Wilcoxon\", \"T\"))\n",
    "        index.append((cntr, \"Wilcoxon\", \"p\"))\n",
    "        \n",
    "        data.append([wilcoxon(results_df[~longonly][hurst_estimator+\"_\"+portfolios[i]], results_df[~longonly][hurst_estimator+\"_\"+portfolios[j]], alternative=\"greater\")[0] for hurst_estimator in hurst_estimators] + [\"\"])\n",
    "        data.append([wilcoxon(results_df[~longonly][hurst_estimator+\"_\"+portfolios[i]], results_df[~longonly][hurst_estimator+\"_\"+portfolios[j]], alternative=\"greater\")[1] for hurst_estimator in hurst_estimators])\n",
    "        data[-1].append(hmean(data[-1]))\n",
    "        \n",
    "        cntr += 1\n",
    "\n",
    "pd.DataFrame(data, index=pd.MultiIndex.from_tuples(index), columns=hurst_estimators+[\"hmp\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b66c083859fa4b281ba145810de44ef54212619bb7543ca293bb406ae2b371fd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
